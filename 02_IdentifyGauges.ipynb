{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c2cfe23",
   "metadata": {},
   "source": [
    "# 02 - Identify Gauges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5b0b2c",
   "metadata": {},
   "source": [
    "This notebook:\n",
    "- Identifies all gauges in the GSDR within 25 km of each landslide and records their distance to the landslide.\n",
    "- Identifies all cities with at least 5 landslides that have nominal rainfall data coverage for further analysis\n",
    "\n",
    "The output of this notebook is: \n",
    "- 'ls_get_gsdr_simple.csv', a csv file of landslides and all nearby gauges from the GSDR that rainfall data should be extracted from.  This file is read into 03_ExtractGSDR\n",
    "\n",
    "**Data required**\n",
    "\n",
    "Processed data: ls_urban_ts_rf_u.pkl\n",
    "\n",
    "Original data: GSDR metadata. This data is not public, please contact the authors in case of questions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b76e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyproj\n",
    "import shapely\n",
    "from shapely.ops import transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd18739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read landslide data.  These are rainfall-triggered urban landslides with a known day.\n",
    "landslides = pd.read_pickle('ls_urban_ts_rf_u.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bc51a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read GSDR metadata file \n",
    "\n",
    "#the GSDR metadata file is not public.  Please contact the authors in case of questions.\n",
    "gsdrmeta = pd.read_excel(\"../QC_Summary_FL13_RB13_01.xlsx\", \n",
    "                        sheet_name = \"QC_Summary_FL13_RB13_01\", \n",
    "                        header = 1, \n",
    "                        usecols = \"A:J\")\n",
    "\n",
    "#convert to a geopandas dataframe\n",
    "gsdrmeta = gpd.GeoDataFrame(gsdrmeta,\n",
    "                                 geometry=gpd.points_from_xy(gsdrmeta.Longitude, gsdrmeta.Latitude),\n",
    "                                 crs = \"EPSG:4326\")\n",
    "\n",
    "\n",
    "#convert record start and end dates to datetime format\n",
    "gsdrmeta['Start Date'] = pd.to_datetime(gsdrmeta['Start Date'])\n",
    "\n",
    "gsdrmeta['End Date'] = pd.to_datetime(gsdrmeta['End Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16927165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns to remove white space\n",
    "gsdrmeta.rename(dict(zip(gsdrmeta.columns, ['Folder', 'OriginalID', 'NewID', 'Latitude', 'Longitude', 'Recordlength(hours)', 'Recordlength(years)', \n",
    "'StartDate', 'EndDate', 'Missingdata(%)', 'geometry'])), axis = 'columns', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f556ee93",
   "metadata": {},
   "source": [
    "### Identify all gauges within 25 km of a landslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba29ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a function \n",
    "\n",
    "def get_stations(lspt, \n",
    "                gsdrmeta,\n",
    "                buffer_dist = 25000):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Function to get the all of the GSDR stations within a defined buffer distance to a landslide point\n",
    "    \n",
    "    lspt = a landslide point (with a DATE and spatial location in WGS84)\n",
    "    gsdrmeta = pandas dataframe with StartDate, EndDate, and a spatial location in in WGS84\n",
    "    buffer_dist = search radius in meters\n",
    "    \n",
    "    Returns a pandas dataframe with all gauges within the defined buffer distance and an indicator of \n",
    "    whether they have data coverage\n",
    "    \n",
    "    \"\"\"\n",
    "   \n",
    "\n",
    "    wgs84 = pyproj.CRS('EPSG:4326')\n",
    "\n",
    "    #define azimuthal equidistant crs centered on the landslide\n",
    "\n",
    "    aeqd = pyproj.Proj(proj='aeqd', ellps='WGS84', datum='WGS84', lat_0=lspt.geometry.y, lon_0=lspt.geometry.x).srs\n",
    "\n",
    "    #reproject the landslide point\n",
    "\n",
    "    project = pyproj.Transformer.from_crs(wgs84, aeqd, always_xy=True).transform\n",
    "    lspt_a = transform(project, lspt.geometry)\n",
    "\n",
    "\n",
    "    #buffer the landlide point\n",
    "    lspt_ab = lspt_a.buffer(buffer_dist)\n",
    "\n",
    "    #reproject the station data \n",
    "    ga = gsdrmeta.to_crs(aeqd)\n",
    "\n",
    "    #get the indices of all stations within 50 km of the landslide point\n",
    "    sidx = ga.sindex.query(lspt_ab, predicate = 'intersects')\n",
    "    \n",
    "    #columns of the metadata dataframe to use as dictionary keys\n",
    "    \n",
    "    gscols = gsdrmeta.columns\n",
    "    \n",
    "    #check if it's empty\n",
    "    \n",
    "    if len(sidx) == 0: \n",
    "        \n",
    "        gageinfo = dict(zip(gscols, [None]*len(gscols)))\n",
    "        \n",
    "        gageinfo['flag'] = 'no close gages'\n",
    "        \n",
    "        gageinfodf = pd.DataFrame([gageinfo])\n",
    "        \n",
    "    else: \n",
    "        \n",
    "        #continue\n",
    "\n",
    "        #these are the stations within the buffer distance of the landslide point\n",
    "        gs = ga.iloc[sidx].copy()\n",
    "\n",
    "        #is there theoretically coverage?\n",
    "        gs['coverage'] = (lspt['DATE'] > gs['StartDate']) & (lspt['DATE'] < gs['EndDate'])\n",
    "        \n",
    "        #check if there's no coverage \n",
    "        \n",
    "        if sum(gs['coverage']) == 0: \n",
    "            \n",
    "            gageinfo = dict(zip(gscols, [None]*len(gscols)))\n",
    "        \n",
    "            gageinfo['flag'] = 'no nominal coverage'\n",
    "            \n",
    "            gageinfodf = pd.DataFrame([gageinfo])\n",
    "        \n",
    "        else: \n",
    "            #continue\n",
    "\n",
    "            #only stations that theoretically have coverage\n",
    "            gsc = gs[gs['coverage']].copy()\n",
    "\n",
    "            #get the distance from the stations to the landslide point\n",
    "            dsl = gsc.distance(lspt_a)\n",
    "\n",
    "            #record the distance\n",
    "            gsc.loc[dsl.index, 'station_dist'] = dsl.values \n",
    "\n",
    "            #project stations back to WGS84\n",
    "            \n",
    "            gsc = gsc.to_crs(wgs84)          \n",
    "\n",
    "            gageinfo = gsc\n",
    "\n",
    "            gageinfo['flag'] = 'coverage'\n",
    "            \n",
    "            gageinfodf = gageinfo.copy()\n",
    "            \n",
    "    gageinfodf['lsidx'] = lspt.name\n",
    "                \n",
    "    return gageinfodf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1872903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all gauges within 25 km of each landslide and compile into one dataframe\n",
    "\n",
    "for l in range(len(landslides)):\n",
    "       \n",
    "    lspt = landslides.iloc[l]\n",
    "    \n",
    "    tempdf = get_stations(lspt, \n",
    "                gsdrmeta,\n",
    "                buffer_dist = 25000)\n",
    "    \n",
    "    if l == 0:\n",
    "        \n",
    "        gageinfo = tempdf.copy()\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        gageinfo = pd.concat([gageinfo, tempdf], axis = 0)\n",
    "    \n",
    "    print('end {}/{}'.format(l, len(landslides)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fa2a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join to landslides dataframe (right join)\n",
    "\n",
    "ls_gages = landslides.merge(gageinfo, \n",
    "                           how = 'right',\n",
    "                            left_index = True,\n",
    "                           right_on = 'lsidx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472cae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset to only landslides with coverage\n",
    "\n",
    "ls_gages_cov = ls_gages[ls_gages['coverage'] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f9dc00",
   "metadata": {},
   "source": [
    "### Identify cities with at least 5 landslides with nominal coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b306091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get landslides that have at least one nearby gauge with coverage\n",
    "\n",
    "ls_gages_cov_one = ls_gages_cov.drop_duplicates('lsidx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ecb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count how many are in each city\n",
    "\n",
    "nls_per_city = ls_gages_cov_one.groupby('ID_HDC_G0').count()['lsidx'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1544840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idgt5 = nls_per_city[nls_per_city>=5].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095dbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flag which landslide/gauge pairs are in a city with >5 landslides\n",
    "ls_gages['gt5'] = ls_gages.apply(lambda row:row['ID_HDC_G0'] in idgt5, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7ce070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset to landslides/gauge pairs with nominal coverage in cities with at least 5 landslides\n",
    "ls_get_gsdr = ls_gages[(ls_gages['coverage'] == True) & (ls_gages['gt5'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35813868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle for safekeeping\n",
    "#ls_get_gsdr.to_pickle('20220908_ls_get_gsdr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c216a008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simplify to columns needed to extract rainfall data \n",
    "\n",
    "ls_get_gsdr_simple = ls_get_gsdr.loc[:, ['inventory', 'src_index', 'inventory_id', 'inventory_id_name', 'lsidx',\n",
    "            'ID_HDC_G0', 'UC_NM_MN', 'date_local_midnight_utc', 'Folder',\n",
    "       'OriginalID', 'NewID', 'Latitude', 'Longitude', 'Recordlength(hours)',\n",
    "       'Recordlength(years)', 'StartDate', 'EndDate', 'Missingdata(%)',\n",
    "       'geometry_y', 'flag', 'coverage', 'station_dist']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c4a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "ls_get_gsdr_simple.to_csv('ls_get_gsdr_simple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935e3ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
