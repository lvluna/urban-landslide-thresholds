{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e231eb9",
   "metadata": {},
   "source": [
    "# 05 - Combine Data and Prepare for Quantile Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6762ea56",
   "metadata": {},
   "source": [
    "This notebook combines and subsets the landslide triggering rainfall and annual maxima datasets.  After these steps, the landslide triggering rainfall data is ready for quantile regression.  \n",
    "\n",
    "\n",
    "**Landslide triggering rainfall data**\n",
    "\n",
    "This notebook combines the following datasets:  \n",
    "1. lsdata_gsdr_rain.csv, which has rainfall data from GSDR gauges within 25 km of a landslide\n",
    "2. lsdata_durban_rain.csv, which has rainfall data from the South African Weather Service within 25 km of a landslide.\n",
    "3. lsdata_medellin_rain.csv, which has rainfall data for Medellin from IDEAM within 25 km of a landslide.\n",
    "\n",
    "It then: \n",
    "1. Filters out gauges that have cumulative precipitation of <0.01 mm in the event period before the landslide\n",
    "2. Finds the closest gauge with fewer than 10% nans in the event period.\n",
    "3. Joins some other information about each landslide and each city\n",
    "4. Subsets to only landslides with a spatial uncertainty of <25 km\n",
    "5. Determines which cities have at least 5 landslides with rainfall data and that meet all criteria\n",
    "\n",
    "**Annual maxima data**\n",
    "\n",
    "This notebook combines the following datasets: \n",
    "1. annual_block_maxima.csv, with annual block maxima at a range of durations from GSDR stations\n",
    "2. annual_block_maxima_durban.csv, with annual block maxima from stations in Durban\n",
    "3. annual_block_maxima_medellin.csv, with annual block maxima from stations in Medellin\n",
    "\n",
    "It then: \n",
    "1. Subsets to gauges that were associated with a landslide\n",
    "2. Filters for annual maxima that have 90% complete data in the year recorded and where the maximum is >0.01 mm\n",
    "\n",
    "**Extended Data Table 1**\n",
    "\n",
    "This notebook also compiles information on the number of landslides, gauges, and lengths of records for Extended Data Table 1.\n",
    "\n",
    "The outputs of this notebook are: \n",
    "- lsdata_rain.csv, which includes rainfall metrics for each landslide for quantile regression\n",
    "- annual_block_maxima_ls_gauges.csv, which includes the annual block maxima at a range of durations for gauges associated with a landslide\n",
    "\n",
    "*These outputs are read into 06_BayesianQuantileRegression*\n",
    "\n",
    "- edtable1.csv, which contains the information for Extended Data Table 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f53a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83198d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set directory with datasets\n",
    "datadir = ''\n",
    "\n",
    "#set directory where results should be saved\n",
    "resultsdir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47adb9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsdata_rain = pd.read_csv('lsdata_rain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82267a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'inventory', 'src_index', 'inventory_id',\n",
       "       'inventory_id_name', 'lsidx', 'ID_HDC_G0', 'UC_NM_MN',\n",
       "       'date_local_midnight_utc', 'Folder', 'OriginalID', 'NewID', 'Latitude',\n",
       "       'Longitude', 'Recordlength(hours)', 'Recordlength(years)', 'StartDate',\n",
       "       'EndDate', 'Missingdata(%)', 'geometry_y', 'flag', 'coverage',\n",
       "       'station_dist', 'event_id', 'tr_start', 'tr_tpk', 'tr_ppk', 'tr_htopk',\n",
       "       'tr_cptopk', 'tr_htoeod', 'tr_cptoeod', 'tr_nnantopk', 'tr_nnan_toeod',\n",
       "       'e_start', 'e_htopk', 'e_cptopk', 'e_htoeod', 'e_cptoeod', 'e_nnantopk',\n",
       "       'e_nnantoeod', 'tr_ante24h', 'tr_ante7d', 'tr_ante14d', 'tr_ante21d',\n",
       "       'tr_ante28d', 'city', 'precip_source', 'perc_nan', 'UC_NM_LST', 'AREA',\n",
       "       'GRGN_L1', 'GRGN_L2', 'CTR_MN_NM', 'E_KG_NM_LST', 'E_SL_LST', 'trigger',\n",
       "       'type', 'material', 'spat_unc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsdata_rain.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b79d78",
   "metadata": {},
   "source": [
    "### combine and subset landslide data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbfd667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all landslides with GSDR data\n",
    "lsdata_gsdr_rain = pd.read_csv(datadir + 'lsdata_gsdr_rain.csv')\n",
    "\n",
    "lsdata_gsdr_rain.drop(['Unnamed: 0'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fe8fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get durban landslides \n",
    "lsdata_durban_rain = pd.read_csv(datadir + 'lsdata_durban_rain.csv')\n",
    "\n",
    "lsdata_durban_rain.drop(['Unnamed: 0'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e1ceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get medellin landslides\n",
    "lsdata_medellin_rain = pd.read_csv(datadir + 'lsdata_medellin_rain.csv')\n",
    "\n",
    "lsdata_medellin_rain.drop(['Unnamed: 0'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae9864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate all rainfall data to get a single dataframe\n",
    "lsdata_all_rain = pd.concat([lsdata_gsdr_rain_updated, lsdata_durban_rain, lsdata_medellin_rain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8910cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get landslide and gauge combinations with data and >0.01 mm of event rainfall\n",
    "lsdata = lsdata_all_rain[(lsdata_all_rain['e_htopk'].notna()) & (lsdata_all_rain['e_cptopk']>0.01)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d670b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the percentage of nans in the event period \n",
    "lsdata['perc_nan'] = lsdata['e_nnantopk']/lsdata['e_htopk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get only events with fewer than 10% nans\n",
    "lsdata = lsdata[lsdata['perc_nan'] < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b85a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each landslide, find the closest gauge.\n",
    "targetdf = lsdata.sort_values('station_dist').drop_duplicates('lsidx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65634d6d",
   "metadata": {},
   "source": [
    "### add attributes for the landslides from the global compilation and attributes for the cities from GHS-UCDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb96c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read global landslide compilation to extract relevant attributes for the considered landslides\n",
    "\n",
    "landslides = pd.read_pickle(datadir + 'ls_urban_ts_rf_u.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b4d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsinfo = landslides.loc[:,['lsidx', 'trigger', 'type', 'material', 'spat_unc', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0412543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates\n",
    "\n",
    "lsinfo = lsinfo.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1bc44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join on some information for these cities\n",
    "\n",
    "#get urban areas \n",
    "#read GHS geopackage (urban areas)\n",
    "urban = gpd.read_file(datadir + '../GHS_STAT_UCDB2015MT_GLOBE_R2019A_V1_2/GHS_STAT_UCDB2015MT_GLOBE_R2019A/GHS_STAT_UCDB2015MT_GLOBE_R2019A_V1_2.gpkg', \n",
    "                       layer = 'GHS_STAT_UCDB2015MT_GLOBE_R2019A_V1_2')\n",
    "\n",
    "\n",
    "#simplify \n",
    "\n",
    "urban = urban.loc[:, ['UC_NM_LST', 'ID_HDC_G0', 'AREA', 'GRGN_L1', 'GRGN_L2', \n",
    "                      'CTR_MN_NM', 'E_KG_NM_LST', 'E_SL_LST']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b763841",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetdf = targetdf.merge(urban, \n",
    "                         how = 'left', \n",
    "                         on = 'ID_HDC_G0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f0fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetdf = targetdf.merge(lsinfo, \n",
    "                         how = 'left', \n",
    "                         on = 'lsidx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679ef7db",
   "metadata": {},
   "source": [
    "get only landslides where the spatial uncertainty is <25 km "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3df536",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetdf = targetdf[targetdf.apply(lambda row : row['spat_unc'] in ['<5km', '<1km', '<10km', '<25km', 'Exact'], axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3483649",
   "metadata": {},
   "source": [
    "### Select cities with at least 5 landslides that meet all criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1c0a10",
   "metadata": {},
   "source": [
    "\n",
    "- have a gauge within 25 km\n",
    "- are rainfall triggered\n",
    "- have available rainfall data\n",
    "- have a spatial uncertainty of <25 km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf8394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts of landslides in each city\n",
    "count_per_city = targetdf.groupby('ID_HDC_G0').count()['inventory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49608820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cities with >5 landslides\n",
    "cities_gt5 = count_per_city[count_per_city >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc75bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset to landslides in cities with >5 landslides\n",
    "targetdf = targetdf[targetdf.apply(lambda row:row['ID_HDC_G0'] in cities_gt5, axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a05be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "targetdf.to_csv(resultsdir + 'lsdata_rain.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc6de76",
   "metadata": {},
   "source": [
    "### Get annual block maxima for gauges associated with landslides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f6acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_block_max_gsdr = pd.read_csv(datadir + 'annual_block_maxima.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50965b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_block_max_gsdr['Date'] = ann_block_max_gsdr['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c36a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_block_max_gsdr.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b17f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_block_max_durban = pd.read_csv(resultsdir + 'annual_block_maxima_durban.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381eb140",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_block_max_medellin = pd.read_csv(resultsdir + 'annual_block_maxima_medellin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0befcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_block_max = pd.concat([ann_block_max_gsdr, ann_block_max_durban, ann_block_max_medellin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94cc358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip city names of white space, special characters, etc for R\n",
    "\n",
    "ann_block_max['city'] = ann_block_max.apply(lambda row:''.join(e for e in row['UC_NM_MN'] if e.isalnum()), \n",
    "                                       axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abaca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_block_max['OriginalID'] = ann_block_max['OriginalID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28322a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get only the gauges that we use in the analysis\n",
    "ls_gauges_unique = pd.DataFrame(targetdf['OriginalID'].unique(), columns = ['OriginalID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb08b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset to those gauges\n",
    "ann_block_max_ls_gauges = pd.merge(ls_gauges_unique, \n",
    "                                  ann_block_max, \n",
    "                                  how = 'left', \n",
    "                                  on = 'OriginalID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492770a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get only entries that have a 90% complete data in each year and where the block max is >0.01\n",
    "ann_block_max_ls_gauges_data = ann_block_max_ls_gauges[(ann_block_max_ls_gauges['raw_notnainmw'] >= 8760*0.90) & \n",
    "                                                      (ann_block_max_ls_gauges['raw_block_max'] >= 0.01)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9a12a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove medellin gauge 27015310 for year 2021 - there is a problem with this data\n",
    "#no landslides were associated with that gauge in 2021, so this only affects the block maxima, not \n",
    "#the landslide data\n",
    "ann_block_max_ls_gauges_data = ann_block_max_ls_gauges_data[(ann_block_max_ls_gauges_data['OriginalID'] != '27015310')\n",
    "                                                           & (ann_block_max_ls_gauges_data['year'] != 2021)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9a47a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_block_max_ls_gauges_data.to_csv(resultsdir + 'annual_block_maxima_ls_gauges.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fa82ff",
   "metadata": {},
   "source": [
    "### Process data for Extended Data Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558cf668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of landslides in each city, earliest and latest landslide on record for each city\n",
    "\n",
    "targetdf['date_local_midnight_utc'] = pd.to_datetime(targetdf['date_local_midnight_utc'])\n",
    "\n",
    "targetdf['year'] = targetdf['date_local_midnight_utc'].dt.year\n",
    "\n",
    "nls = targetdf.groupby('city').count()['lsidx']\n",
    "\n",
    "earlyls = targetdf[['city', 'year']].groupby('city').min()['year']\n",
    "\n",
    "latels = targetdf[['city', 'year']].groupby('city').max()['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46f1d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of gauges in each city, earliest and latest year of precipitation records\n",
    "\n",
    "earlygauge = ann_block_max_ls_gauges_data[['city', 'year']].groupby('city').min()['year']\n",
    "\n",
    "lategauge = ann_block_max_ls_gauges_data[['city', 'year']].groupby('city').max()['year']\n",
    "\n",
    "ann_block_max_ls_gauges_data_unique = ann_block_max_ls_gauges_data.drop_duplicates(subset = ['OriginalID', 'city'])\n",
    "\n",
    "ngauge = ann_block_max_ls_gauges_data_unique.groupby('city').count()['OriginalID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b55bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extended data table 1\n",
    "edtable1 = pd.DataFrame([nls, earlyls, latels, ngauge, earlygauge, lategauge]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bd8eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "edtable1.to_csv('edtable1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
